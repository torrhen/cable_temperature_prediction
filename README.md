Cable joint temperature prediction using recurrent neural network (RNN), long short term memory (LSTM) and Gated Recurrent Unit (GRU) models.

The following input variables are used to train each model to predict the target variable "Thermocouple 5":
- Thermocouple 1
- Thermocouple 2
- Thermocouple 3
- Thermocouple 4
- Thermocouple 6
- Thermocouple 7
- Phase (Blue) (Current)
- Phase (Yellow) (Current)
- Phase (Red) (Current)

The data is split into three, chronological datasets ensuring no data leakage based on 80:10:10 split. Each dataset covers the following periods:
- Train data [19/03/2015 - 25/08/2015]
- Validation data [26/08/2015 - 14/09/2015]
- Test Data [15/09/2015 - 04/10/2015]

The following steps are used to clean, preprocess, train and evaulate the model:
1. Read in the full data as a data frame, converting the timestamp column to a datetime index.
2. Resample the full date for every five minute interval. Additional empty rows generated by this step, just to prolonged periods of no data are forwarded filled with the last observation.
3. The train dataset is created using the criteria outlined above.
4. All datasets are made by creating window samples with a size of 12. This equates to predicting the immediate cable joint temperature based on the previous hour of time series, input data.
5. Along with each sample window, the differences of each sample in the sequence is calculated, for every feature, along with summuary statistics for each individual window. These include: min, max, median, mean and variance.
6. Once the training dataset has been set up, the global mean and standard deviation of every feature (including the difference between samples) across the dataset is calculated. These normalisation statistics are used to normalise all three datasets.
7. The validation and test data are created in the same way (excluding calculation of normalisation statistics). The sample windows within the training data and validation are shuffled (temporal features within each window are still preserved). The order of the test data is preserved for the purposes of evaluating and plotting model predictions.
8. During training, each input sample window is augmented randomly to synetise greater variety in the training data to improve generalisation on the test data and increase model robustness. These include adding some small about of gaussian noise (Gaussian Nosie()), scaling the sequence of samples by some small scalar (ScalingSequence()) and permuting the order of some small subset of the sample window (PermuteSequence()). This is performed on the training data ONLY.
9. After augmentation, the differences between samples within each window as well as the summary statistics are recalculated to capture any changes. 
10. Each sample window, its differences and summary statistics, is then normalisaed using the mean and standard deviation of the original training data calculated earlier. Values are then clipped to be within the interval [-3, 3].
11. The model state correpsonding to the epoch that achieves the lowest validation mean squared error loss is evaluated on the test data. Both the error and predictions are plotted for the test data and compared with the true values.
